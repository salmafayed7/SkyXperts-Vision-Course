{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "603ac0a1",
   "metadata": {},
   "source": [
    "# Computer Vision Assignments: Sessions 1 & 2\n",
    "\n",
    "This notebook contains tasks and assignments based on Sessions 1 and 2. You are required to implement the functions and complete the exercises as described. Use OpenCV and other necessary libraries like NumPy and Matplotlib.\n",
    "\n",
    "**Instructions:**\n",
    "- Complete each task in the provided code cells.\n",
    "- Test your implementations with sample images (e.g., download test images [here](https://sipi.usc.edu/database/database.php?volume=misc) or [here](https://www.hlevkin.com/hlevkin/06testimages.htm) or use your own test images).\n",
    "- Include comments in your code for clarity.\n",
    "- Display results using cv2.imshow() or Matplotlib where appropriate.\n",
    "- Submit the completed notebook along with any output images or explanations on [our google drive for the CV sessions](https://drive.google.com/drive/folders/1IjVhJmAXxNQTGT-ybJ-yc5smYtR5v8CO?usp=sharing) **upload your files in a new folder under your name**\n",
    "\n",
    "## Session 1: Basic Image Operations (Reading, Resizing, Cropping, Rotating)\n",
    "\n",
    "### Task 1: Read and Display an Image\n",
    "Read an image from a file and display it in both BGR and grayscale formats. Handle errors if the image cannot be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Your code here\n",
    "path = \"dogBGR.jpg\"  # Replace with your image path\n",
    "\n",
    "# Read in BGR\n",
    "img = cv.imread(path)\n",
    "\n",
    "# Read in Grayscale\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display both using cv.imshow() or plt.imshow()\n",
    "cv.imshow(\"dog\", img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"gray dog\", gray_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Resize Image with Aspect Ratio Preservation\n",
    "Implement resizing while preserving aspect ratio. Downscale to 60% and upscale to 200%. Compare shapes and display originals vs resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Load image\n",
    "\n",
    "# Downscale to 60%\n",
    "scale_factor = 60\n",
    "h, w, _ = img.shape\n",
    "h = int(scale_factor * h / 100)\n",
    "w = int(scale_factor * w / 100)\n",
    "dim = (h, w)\n",
    "down_img = cv.resize(img, dim , interpolation = cv.INTER_AREA)\n",
    "\n",
    "# Upscale to 200%\n",
    "scale_factor = 200\n",
    "h, w, _ = img.shape\n",
    "h = int(scale_factor * h / 100)\n",
    "w = int(scale_factor * w / 100)\n",
    "dim = (h, w)\n",
    "up_img = cv.resize(img, dim , interpolation = cv.INTER_AREA)\n",
    "\n",
    "# Display all three\n",
    "cv.imshow(\"dog\", img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"small dog\", down_img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"big dog\", up_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Resize Without Preserving Aspect Ratio\n",
    "Resize only width to 100 pixels, only height to 200 pixels, and both to (200, 200). Display and discuss distortions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "h,w , _ = img.shape\n",
    "h = h\n",
    "w = 100\n",
    "dim = (h, w)\n",
    "wide = cv.resize(img, dim , interpolation = cv.INTER_AREA)\n",
    "cv.imshow(\"wide dog\", wide)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Resize Using Scale Factors (fx, fy)\n",
    "Scale up by 1.2 in both directions and down by 0.6. Use different interpolations (INTER_LINEAR, INTER_NEAREST) and compare quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "scale_up_x = 1.2\n",
    "scale_up_y = 1.2\n",
    "scale_down = 0.6\n",
    "scaled_down = cv.resize(img, None, fx= scale_down, fy= scale_down, interpolation= cv.INTER_LINEAR)\n",
    "scaled_up = cv.resize(img, None, fx= scale_up_x, fy= scale_up_y, interpolation= cv.INTER_LINEAR)\n",
    "\n",
    "cv.imshow(\"dog\", img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"small dog\", scaled_down)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"big dog\", scaled_up)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Experiment with interpolations\n",
    "scaled_down_nearest = cv.resize(img, None, fx= scale_down, fy= scale_down, interpolation= cv.INTER_NEAREST)\n",
    "scaled_up_nearest = cv.resize(img, None, fx= scale_up_x, fy= scale_up_y, interpolation= cv.INTER_NEAREST)\n",
    "cv.imshow(\"small dog nearest\", scaled_down_nearest)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"big dog nearest\", scaled_up_nearest)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Cropping an Image\n",
    "Crop a region (e.g., [20:200, 50:200]) from the image. Display original and cropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "cropped = img[20:200 , 50:200]\n",
    "cv.imshow(\"og dog\", img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"earless dog\", cropped)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Advanced Cropping - Patch Image into Blocks\n",
    "Divide the image into 4 equal blocks (2x2 grid) by cropping. Display each block separately and then stitch them back using NumPy concatenation to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Calculate midpoints for height and width\n",
    "h, w, _ = img.shape\n",
    "h_mid = h // 2\n",
    "w_wid = w // 2\n",
    "\n",
    "# Crop into top-left, top-right, bottom-left, bottom-right\n",
    "top_left = img[:h_mid, :w_wid]\n",
    "top_right = img[:h_mid, w_wid:]\n",
    "bottom_left = img[h_mid:, :w_wid]\n",
    "bottom_right = img[h_mid:, w_wid:]\n",
    "# Display each\n",
    "titles = [\"Top Left\", \"Top Right\", \"Bottom Left\", \"Bottom Right\"]\n",
    "blocks = [top_left, top_right, bottom_left, bottom_right]\n",
    "\n",
    "for i, block in enumerate(blocks):\n",
    "    cv.imshow(f\"Block {i+1}\", block)\n",
    "    cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Stitch back (use np.hstack and np.vstack)\n",
    "top = np.concatenate((top_left, top_right), axis=1)\n",
    "bottom = np.concatenate((bottom_left, bottom_right), axis=1)\n",
    "stitched = np.concatenate((top, bottom), axis=0)\n",
    "cv.imshow(\"back together\", stitched)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Rotating an Image\n",
    "Rotate the image by 45째, 90째, and 180째 using getRotationMatrix2D and warpAffine. Display all rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "# Calculate center\n",
    "h, w, _ = img.shape\n",
    "center = (h / 2, w / 2)\n",
    "# For each angle: get matrix, warp, display\n",
    "angle45matrix = cv.getRotationMatrix2D(center=center, angle=45, scale=1)\n",
    "angle45image = cv.warpAffine(src=img, M=angle45matrix, dsize=(w, h))\n",
    "cv.imshow(\"og dog\", img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"slightly rotated dog\", angle45image)\n",
    "cv.waitKey(0)\n",
    "\n",
    "angle90matrix = cv.getRotationMatrix2D(center=center, angle=90, scale=1)\n",
    "angle90image = cv.warpAffine(src=img, M=angle90matrix, dsize=(w, h))\n",
    "cv.imshow(\"mid rotated dog\", angle90image)\n",
    "cv.waitKey(0)\n",
    "\n",
    "angle180matrix = cv.getRotationMatrix2D(center=center, angle=180, scale=1)\n",
    "angle180image = cv.warpAffine(src=img, M=angle180matrix, dsize=(w, h))\n",
    "cv.imshow(\"heavily rotated dog\", angle180image)\n",
    "cv.waitKey(0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Rotate with Scaling\n",
    "Rotate by 45째 and scale by 0.5 in **one** operation. Compare with separate resize and rotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "angle45matrixplusrotate = cv.getRotationMatrix2D(center=center, angle=45, scale=0.5)\n",
    "angle45imageplusrotate = cv.warpAffine(src=img, M=angle45matrixplusrotate, dsize=(w, h))\n",
    "cv.imshow(\"not resized\", angle45image)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"resized\", angle45imageplusrotate)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 2: Image Acquisition, Formats, Color Spaces, Enhancement, and Filtering\n",
    "\n",
    "### Task 9: Read Image in Different Color Spaces\n",
    "Read an image in BGR, convert to RGB (for Matplotlib), HSV, LAB and Grayscale. Display all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Use cv.cvtColor()\n",
    "RGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "HSV = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "LAB = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "images = [img, gray_img, RGB, HSV, LAB]\n",
    "for i, pic in enumerate(images):\n",
    "    cv.imshow(\"color\", pic)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Image Sharpening\n",
    "Apply cv2.blur() with a 5x5 kernel, then use cv2.filter2D() with sharpening kernels of varying strengths (e.g., [[0, -1, 0], [-1, 5, -1], [0, -1, 0]] and [[0, -2, 0], [-2, 9, -2], [0, -2, 0]]).\n",
    "Compare between original and sharpened image after blurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Use cv2.blur\n",
    "blurred = cv.blur(img, (5,5))\n",
    "# Define sharpen kernel, use cv.filter2D()\n",
    "kernel1 = np.array([[0, -1, 0],\n",
    "                    [-1,  5, -1],\n",
    "                    [0, -1, 0]])\n",
    "\n",
    "kernel2 = np.array([[0, -2, 0],\n",
    "                    [-2,  9, -2],\n",
    "                    [0, -2, 0]])\n",
    "\n",
    "sharpened1 = cv.filter2D(blurred, -1, kernel1)\n",
    "sharpened2 = cv.filter2D(blurred, -1, kernel2)\n",
    "\n",
    "cv.imshow(\"og\", img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"blurred\", blurred)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"lightly sharpened\", sharpened1)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"strongly sharpened\", sharpened2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11: Add Salt and Pepper Noise to Image\n",
    "Implement a function to add salt and pepper noise to an image. Control noise density (e.g., 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from skimage.util import random_noise\n",
    "def add_salt_pepper_noise(image, density=0.05):\n",
    "    # Implement using random pixels set to 0 or 255\n",
    "    noisy = random_noise(img, mode = \"s&p\", amount = density)\n",
    "    noisy = np.array(255 * noisy, dtype = \"uint8\")\n",
    "    return noisy\n",
    "# Apply to an image and display\n",
    "noisy = add_salt_pepper_noise(img, 0.05)\n",
    "cv.imshow(\"noisy\", noisy)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: Remove Salt and Pepper Noise Using Median Filter\n",
    "Apply cv.medianBlur() to a noisy image. Experiment with kernel sizes (3,5,7) and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "medianFilter = cv.medianBlur(noisy, 5)\n",
    "cv.imshow(\"median\", medianFilter)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13: Implement Adaptive Median Filter\n",
    "Write a custom function for adaptive median filtering. It should dynamically increase window size until noise is removed or max size is reached. Apply to a noisy image and compare with standard median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af5321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive Median Filter\n",
    "\n",
    "def adaptive_median_filter(image, max_size):\n",
    "    h, w = image.shape\n",
    "    pad = max_size // 2\n",
    "    padded = cv.copyMakeBorder(image, pad, pad, pad, pad, cv.BORDER_REFLECT)\n",
    "    out = np.zeros_like(image)\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            S = 3\n",
    "            while True:\n",
    "                window = padded[i:i+S, j:j+S]\n",
    "                Zmin, Zmax = window.min(), window.max()\n",
    "                Zmed = np.median(window)\n",
    "                Zxy = padded[i+pad, j+pad]\n",
    "\n",
    "                if Zmed > Zmin and Zmed < Zmax:  \n",
    "                    if Zxy > Zmin and Zxy < Zmax:  \n",
    "                        out[i, j] = Zxy\n",
    "                    else:\n",
    "                        out[i, j] = Zmed\n",
    "                    break\n",
    "                else:\n",
    "                    S += 2\n",
    "                    if S > max_size:\n",
    "                        out[i, j] = Zmed\n",
    "                        break\n",
    "    return out.astype(\"uint8\")\n",
    "\n",
    "\n",
    "img = cv.imread(\"dogBGR.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "noisy = random_noise(img, mode=\"s&p\", amount=0.05)\n",
    "noisy = (255 * noisy).astype(\"uint8\")\n",
    "\n",
    "median_std = cv.medianBlur(noisy, 3)\n",
    "median_adapt = adaptive_median_filter(noisy, max_size=3)\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.imshow(\"Noisy\", noisy)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.imshow(\"Median (3x3)\", median_std)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.imshow(\"Adaptive Median\", median_adapt)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14: Implement Bilateral Filter Function\n",
    "Write a Python function to perform bilateral filtering on an image. Use Gaussian weights for both spatial and intensity. Parameters: diameter, sigma_color, sigma_space. Compare with cv.bilateralFilter()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def custom_bilateral_filter(image, diameter, sigma_color, sigma_space):\n",
    "    h, w = image.shape\n",
    "    pad = diameter // 2\n",
    "    padded = cv.copyMakeBorder(image, pad, pad, pad, pad, cv.BORDER_REFLECT)\n",
    "\n",
    "    # Precompute spatial Gaussian weights\n",
    "    y, x = np.mgrid[-pad:pad+1, -pad:pad+1]\n",
    "    spatial_weights = np.exp(-(x**2 + y**2) / (2 * sigma_space**2))\n",
    "\n",
    "    output = np.zeros_like(image, dtype=np.float64)\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            region = padded[i:i+diameter, j:j+diameter]\n",
    "            intensity_diff = region - image[i, j]\n",
    "            range_weights = np.exp(-(intensity_diff**2) / (2 * sigma_color**2))\n",
    "            \n",
    "            # Total weight = spatial * range\n",
    "            weights = spatial_weights * range_weights\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            output[i, j] = np.sum(region * weights)\n",
    "\n",
    "    return output.astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "img = cv.imread(\"dogBGR.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "custom = custom_bilateral_filter(img, diameter=5, sigma_color=100, sigma_space=100)\n",
    "opencv = cv.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"Custom Bilateral\", custom)\n",
    "cv.waitKey(0)\n",
    "cv.imshow(\"OpenCV Bilateral\", opencv)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [BONUS] Task 15: Comprehensive Camera Task \n",
    "Combine: Live camera feed -> grayscale -> add noise -> remove with median -> sharpen. Display all stages in separate windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read video from camera example:\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "\n",
    "camera_id = 0\n",
    "delay = 1\n",
    "\n",
    "windows = ['og', 'gray', 'noisy', 'median filter', 'sharpened']\n",
    "\n",
    "cap = cv.VideoCapture(camera_id)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    sys.exit()\n",
    "\n",
    "sharpen_kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5,-1],\n",
    "                           [0, -1, 0]])\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    noisy = random_noise(gray, mode=\"s&p\", amount=0.05)\n",
    "    noisy = (255 * noisy).astype(np.uint8)\n",
    "    medianFilter = cv.medianBlur(noisy, 5)\n",
    "    sharpened = cv.filter2D(medianFilter, -1, sharpen_kernel)\n",
    "\n",
    "    results = [frame, gray, noisy, medianFilter, sharpened]\n",
    "\n",
    "    for win_name, img in zip(windows, results):\n",
    "        cv.imshow(win_name, img)\n",
    "        key = cv.waitKey(delay) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            cap.release()\n",
    "            cv.destroyAllWindows()\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [BONUS]Task 16: Comprehensive Video Task\n",
    "Similar to Task 18 but for a video file. Save the final processed video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "\n",
    "delay = 1\n",
    "\n",
    "windows = ['og', 'gray', 'noisy', 'median filter', 'sharpened']\n",
    "\n",
    "cap = cv.VideoCapture(r'C:\\Users\\rsl_f\\OneDrive\\Desktop\\shows\\severance\\Severance S02E07.mkv')\n",
    "\n",
    "sharpen_kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5,-1],\n",
    "                           [0, -1, 0]])\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    noisy = random_noise(gray, mode=\"s&p\", amount=0.05)\n",
    "    noisy = (255 * noisy).astype(np.uint8)\n",
    "    medianFilter = cv.medianBlur(noisy, 5)\n",
    "    sharpened = cv.filter2D(medianFilter, -1, sharpen_kernel)\n",
    "\n",
    "    results = [frame, gray, noisy, medianFilter, sharpened]\n",
    "\n",
    "    for win_name, img in zip(windows, results):\n",
    "        cv.imshow(win_name, img)\n",
    "        key = cv.waitKey(delay) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            cap.release()\n",
    "            cv.destroyAllWindows()\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 17: Performance Comparison\n",
    "Time the execution of standard median vs adaptive median on a large noisy image. Discuss when adaptive median filter is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard median filter time: 0.003565549850463867 seconds\n",
      "adaptive median filter time 29.75269603729248 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Your code here\n",
    "# Use time.time() to measure\n",
    "\n",
    "img = cv.imread(\"dogBGR.jpg\")\n",
    "noisy = random_noise(gray, mode=\"s&p\", amount=0.05)\n",
    "noisy = (255 * noisy).astype(np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "median_std = cv.medianBlur(noisy, 5)\n",
    "end = time.time()\n",
    "print(\"standard median filter time:\", end - start, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "median_adapt = adaptive_median_filter(noisy, max_size=3)\n",
    "end = time.time()\n",
    "print(\"adaptive median filter time\", end - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1fd2b",
   "metadata": {},
   "source": [
    "adaptive median filter is better for images with much more noise and it retains the edge info in the case of hgih density impluse noises, so it's best for when there's a need for denoising as well as preserving detail info. its limitation is that it takes much longer time since the standard median filter is a built-in function and uses a fixed window size. adaptive median filter checks variable windows sizes, hence taking up more time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb40d14",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
